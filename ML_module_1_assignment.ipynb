{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# modelue 2: Feature Engineering assignment"
      ],
      "metadata": {
        "id": "iCQgq1YtjbEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "-> a parameter is an internal variable within a model that the algorithm learns from the training data to make accurate predictions, such as weights and biases in neural networks or coefficients in linear regression."
      ],
      "metadata": {
        "id": "sRvoWZfljvQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation? What does negative correlation mean?\n",
        "-> correlation : correlation measures the statistical relationship between two variables, indicating the strength and direction of their linear association, ranging from -1 (strong negative) to +1 (strong positive), with 0 indicating no linear relationship.\n",
        "*  negative correlation: a negative correlation (or inverse correlation) means that as one variable increases, the other variable tends to decrease, and vice versa.\n"
      ],
      "metadata": {
        "id": "V8Bw1vwsj2nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "-> Machine learning is a subset of artificial intelligence that focuses on enabling computers to learn from data without explicit programming, using algorithms to identify patterns and make predictions or decisions. The main components are algorithms, data, models, and training/evaluation."
      ],
      "metadata": {
        "id": "2upZDM1DkINl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "-> a lower loss value generally indicates a better-performing model, as it signifies that the model's predictions are closer to the actual values."
      ],
      "metadata": {
        "id": "39EqhibPkSGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "-> continuous variables represent measurable values within a range (e.g., height, weight, temperature), while categorical variables represent distinct categories or groups (e.g., gender, color, product type)."
      ],
      "metadata": {
        "id": "962YJsr_kbhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "-> To handle categorical variables in machine learning, common techniques include label encoding, one-hot encoding, and ordinal encoding, which convert categorical data into a numerical format suitable for model training."
      ],
      "metadata": {
        "id": "eiHkLiuYkhnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "-> “Training data teaches a machine learning model how to behave while testing data evaluates how well the model has learned.” 1. Training data is used to teach the machine learning model how to make predictions or perform a desired task."
      ],
      "metadata": {
        "id": "piO_3mj-kq1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "-> The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators. In general, learning algorithms benefit from standardization of the data set."
      ],
      "metadata": {
        "id": "i4tN1VyxkvGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "-> The test set is a portion (or partition) of the available training data that is “held back” and not used during model training. The purpose of the test set is to evaluate the performance of the model on unseen data after it has been trained."
      ],
      "metadata": {
        "id": "stTHtDFBk0wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "# -> you split data for training and testing using the train_test_split function from scikit-learn, which randomly divides the dataset into training and testing subsets, allowing for unbiased model evaluation.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X =  # Your feature data\n",
        "y =  # Your target data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ->approach any Machine Learning problem\n",
        "# Study, Understand, And Analyze the Problem. ...\n",
        "# Data Collection and Understanding. ...\n",
        "# Preprocessing. ...\n",
        "# Selection of ML Model and Building. ...\n",
        "# Improve the selected model. ...\n",
        "# Test and Validate The Model. ...\n",
        "# Deploy the selected model. ...\n",
        "# Process Iteration."
      ],
      "metadata": {
        "id": "zCNPFm5JlNBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "-> Performing EDA (Exploratory Data Analysis) before fitting a model is crucial because it helps you understand the data's structure, identify potential issues (like outliers or missing values), and inform the model-building process by revealing patterns and relationships that might otherwise be missed, leading to better model performance."
      ],
      "metadata": {
        "id": "q0v03PM5luqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "-> In Machine Learning (ML), correlation refers to the statistical relationship or association between two or more variables, indicating how one variable changes in relation to another. It measures the strength and direction of this relationship, helping to understand how features might influence each other or the target variable."
      ],
      "metadata": {
        "id": "Zq2-YSWSl23Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "-> a negative correlation means that as one variable increases, the other variable tends to decrease, indicating an inverse relationship between them."
      ],
      "metadata": {
        "id": "FUT6nSKmmKSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "-> This can be done by calculating a matrix of the relationships between each pair of variables in the dataset. The result is a symmetric matrix called a correlation matrix with a value of 1.0 along the diagonal as each column always perfectly correlates with itself."
      ],
      "metadata": {
        "id": "zOe4Q1nanb-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "-> causation refers to a cause-and-effect relationship where one event directly influences another, while correlation simply indicates a relationship or association between two events, without implying causation."
      ],
      "metadata": {
        "id": "hKV0MB60oJA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "-> an optimizer is an algorithm that adjusts model parameters (like weights and biases) during training to minimize the loss function, leading to improved model performance. Common optimizers include Gradient Descent, Stochastic Gradient Descent (SGD), Adam, and RMSprop."
      ],
      "metadata": {
        "id": "ItH5YVZloQw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "-> linear_model is a class of the sklearn module if contain different functions for performing machine learning with linear models. The term linear model implies that the model is specified as a linear combination of features."
      ],
      "metadata": {
        "id": "xEOo_pExoXkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "-> In Machine Learning, `model.fit()` is used to train the model on the given training data. It finds the best parameters by learning patterns from input features (`X`) and corresponding labels (`y`). The key arguments usually required are:\n",
        "\n",
        "- `X`: Input data (features)  \n",
        "- `y`: Target data (labels)  \n",
        "- Optional: `epochs`, `batch_size`, `validation_data`, etc. (mostly in deep learning frameworks)\n"
      ],
      "metadata": {
        "id": "bnncYguDoghG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "-> In Machine Learning, `model.predict()` is used to make predictions on new or unseen data after the model has been trained. It takes input features and returns the model's output (e.g., class labels or values).\n",
        "\n",
        "- Argument: `X` (new input data for prediction)"
      ],
      "metadata": {
        "id": "uop369IspA7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are continuous and categorical variables?\n",
        "-> continuous variables represent measurable quantities with an infinite number of values within a range (e.g., height, weight), while categorical variables represent distinct categories or groups (e.g., gender, color)."
      ],
      "metadata": {
        "id": "RB1KBmJWpORN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "-> Feature scaling is a data preprocessing technique that normalizes the range of input features in a dataset, ensuring all features contribute equally to the model's learning process, leading to faster and more stable convergence, especially for algorithms sensitive to feature magnitude."
      ],
      "metadata": {
        "id": "oert86lPpWk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "-> you can perform data scaling (normalization or standardization) using the scikit-learn library, specifically the MinMaxScaler and StandardScaler classes, which allow you to transform data to a specific range or a standard normal distribution."
      ],
      "metadata": {
        "id": "lEf9wuYxpcyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "-> The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators."
      ],
      "metadata": {
        "id": "DHfApIaDpiNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "-> To split data for model fitting in Python, you can use the train_test_split function from scikit-learn, which randomly divides the dataset into training and testing subsets.\n",
        "- from sklearn.model_selection import train_test_split\n",
        "- X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xFT9avXbpnpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain data encoding?\n",
        "-> data encoding is the process of converting categorical or textual data into a numerical format suitable for algorithms, which typically work with numbers rather than text or categories. This is a crucial preprocessing step for preparing data for ML models."
      ],
      "metadata": {
        "id": "v29qcMgXrICF"
      }
    }
  ]
}